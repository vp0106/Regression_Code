import numpy as np
import pandas as pd
import math as math
import random as rand
import scipy as scp
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error

a = 1103515425
c = 12345
m = 2**32
n = rand.randint(100000,m)
mylist = []
mylist.append(n)
for i in range (0,1000) : 
    n = (a*n + c) % m
    mylist.append(n)
listofpairs = []
currenttuple = ()
for i in range(len(mylist)-1):
    currenttuple = (mylist[i], mylist[i+1])
    listofpairs.append(currenttuple)
data = pd.DataFrame.from_records(listofpairs, columns=['x', 'y'])
print(data)
X = data.iloc[:,0].values.reshape(-1,1)
Y = data.iloc[:,1].values.reshape(-1,1)
x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size = 0.2, random_state = n)

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X, Y)

from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=2)
X_poly = poly_reg.fit_transform(X)
pol_reg = LinearRegression()
pol_reg.fit(X_poly, Y)

# Visualizing the Polymonial Regression results
def viz_polymonial():
    plt.scatter(X, Y, color='red')
    plt.plot(X, pol_reg.predict(poly_reg.fit_transform(X)), color='blue')
    plt.title('Polynomial Regression Analysis')
    plt.xlabel('Xvalues')
    plt.ylabel('Yvalues')
    plt.show()
    return
viz_polymonial()
testnumber1 = Y[999]
Y_of_testnumber1 = (a*testnumber1 + c) % m
ch = ","
print(testnumber1, ch, Y_of_testnumber1)
Predicted_Y_Test_Value = pol_reg.predict(poly_reg.fit_transform([testnumber1]))
print("Predicted Value = ", Predicted_Y_Test_Value)
R_square = r2_score(X, Y)
print("R^2 = ", R_square)
MAE = mean_absolute_error(x_test, y_test)
print("MAE = ", MAE)
